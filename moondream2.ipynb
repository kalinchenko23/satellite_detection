{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dba2b4-24d0-450d-9934-f94325cdf260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure CUDA is available and working\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808d3de-22f5-40ee-98af-6cf5960fb2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download moondream2\n",
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "model_id = \"vikhyatk/moondream2\"\n",
    "revision = \"2025-06-21\"  \n",
    "local_folder = \"./moondream_weights\"\n",
    "\n",
    "print(f\"Starting download of {model_id} (Revision: {revision})...\")\n",
    "\n",
    "# Download the model files\n",
    "local_model_path = snapshot_download(\n",
    "    repo_id=model_id,\n",
    "    revision=revision,\n",
    "    local_dir=local_folder,\n",
    "    local_dir_use_symlinks=False, \n",
    "    ignore_patterns=[\"*.md\", \"*.gitattributes\"] \n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Download complete! Model saved to: {os.path.abspath(local_model_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e15d7e-0710-4fac-8de3-dae55f5a10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## COPY FILES FROM CACHE ##############################################\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Source and destination paths\n",
    "SOURCE_PATH = os.path.expanduser(\"~/moondream_weights\")\n",
    "BASE_DIR = Path(__file__).resolve().parent\n",
    "SOURCE_PATH = BASE_DIR / \"moondream_weights\"\n",
    "\n",
    "# Create the cache directory\n",
    "os.makedirs(CACHE_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Copying files from {SOURCE_PATH}\")\n",
    "print(f\"üìÇ To cache location: {CACHE_PATH}\")\n",
    "\n",
    "# Copy all Python files and config files\n",
    "files_to_copy = [\n",
    "    \"lora.py\",\n",
    "    \"layers.py\", \n",
    "    \"configuration_moondream.py\",\n",
    "    \"vision_encoder.py\",\n",
    "    \"config.json\",\n",
    "    \"region_model.py\",\n",
    "    \"rope.py\",\n",
    "    \"fourier_features.py\"\n",
    "]\n",
    "\n",
    "for filename in files_to_copy:\n",
    "    src = os.path.join(SOURCE_PATH, filename)\n",
    "    dst = os.path.join(CACHE_PATH, filename)\n",
    "    \n",
    "    if os.path.exists(src):\n",
    "        shutil.copy2(src, dst)\n",
    "        print(f\"‚úÖ Copied {filename}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {filename} not found (might not be needed)\")\n",
    "\n",
    "print(\"üéâ Setup complete! Try running your code again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de7ce4b-5242-4861-b75e-4ecf5fcef716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Loading Model...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     16\u001b[39m MODEL_PATH = os.path.expanduser(\u001b[33m\"\u001b[39m\u001b[33m~/moondream_weights\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m sys.path.append(MODEL_PATH)\n\u001b[32m     19\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.eval()\n\u001b[32m     25\u001b[39m tokenizer = AutoTokenizer.from_pretrained(\n\u001b[32m     26\u001b[39m     MODEL_PATH, \n\u001b[32m     27\u001b[39m     trust_remote_code=\u001b[38;5;28;01mTrue\u001b[39;00m,  \n\u001b[32m     28\u001b[39m     local_files_only=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     29\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Model Loaded! Ready for images.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/detecting_model/lib/python3.12/site-packages/transformers/modeling_utils.py:4343\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   4338\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   4339\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4340\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4341\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4342\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m4343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/detecting_model/lib/python3.12/site-packages/torch/nn/modules/module.py:1371\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1369\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/detecting_model/lib/python3.12/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/detecting_model/lib/python3.12/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/detecting_model/lib/python3.12/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    935\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    940\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    941\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/detecting_model/lib/python3.12/site-packages/torch/nn/modules/module.py:957\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    953\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    954\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    955\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    956\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/detecting_model/lib/python3.12/site-packages/torch/nn/modules/module.py:1357\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1351\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1352\u001b[39m             device,\n\u001b[32m   1353\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1354\u001b[39m             non_blocking,\n\u001b[32m   1355\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1356\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/detecting_model/lib/python3.12/site-packages/torch/cuda/__init__.py:410\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    414\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "################################################ LOAD MODEL ################################################################## \n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "os.environ['HF_DATASETS_OFFLINE'] = '1'\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "print(\"‚è≥ Loading Model...\")\n",
    "\n",
    "MODEL_PATH = os.path.expanduser(\"~/moondream_weights\")\n",
    "sys.path.append(MODEL_PATH)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH, \n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True\n",
    ").to(\"cuda\").eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_PATH, \n",
    "    trust_remote_code=True,  \n",
    "    local_files_only=True\n",
    ")\n",
    "print(\"‚úÖ Model Loaded! Ready for images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882d496e-97e5-4b5f-b6ae-296edacfe6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# RESTITCH TILES ########################################################################\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "def restitch_and_draw(tile_dir, output_path, original_size, tile_size, overlap, detections):\n",
    "    \"\"\"\n",
    "    tile_dir: Directory where tiles are stored\n",
    "    output_path: Where to save the final stitched image\n",
    "    original_size: Tuple (width, height) of the original large image\n",
    "    tile_size: int (e.g., 512)\n",
    "    overlap: int (e.g., 64)\n",
    "    detections: List of dicts: {'tile_name': ..., 'boxes': [{'x_min', 'y_min', 'x_max', 'y_max'}, ...]}\n",
    "    \"\"\"\n",
    "    # 1. Initialize a new canvas\n",
    "    canvas = Image.new('RGB', original_size)\n",
    "    step = tile_size - overlap\n",
    "    \n",
    "    # 2. Place tiles on the canvas (Restitching)\n",
    "    for filename in sorted(os.listdir(tile_dir)):\n",
    "        if not filename.endswith(('.tif', '.png')): continue\n",
    "        \n",
    "        # Parse row and column from filename (regex for _rXXXX_cXXXX)\n",
    "        match = re.search(r'_r(\\d+)_c(\\d+)', filename)\n",
    "        if match:\n",
    "            row, col = int(match.group(1)), int(match.group(2))\n",
    "            tile = Image.open(os.path.join(tile_dir, filename))\n",
    "            \n",
    "            # Global position calculation\n",
    "            x_offset = col * step\n",
    "            y_offset = row * step\n",
    "            canvas.paste(tile, (x_offset, y_offset))\n",
    "\n",
    "    # 3. Translate and Draw Bounding Boxes\n",
    "    draw = ImageDraw.Draw(canvas)\n",
    "    for det in detections:\n",
    "        tile_name = det['tile_name']\n",
    "        match = re.search(r'_r(\\d+)_c(\\d+)', tile_name)\n",
    "        if not match: continue\n",
    "        \n",
    "        row, col = int(match.group(1)), int(match.group(2))\n",
    "        x_offset = col * step\n",
    "        y_offset = row * step\n",
    "        \n",
    "        for box in det['objects']:\n",
    "            gx1 = (box['x_min'] * tile_size) + x_offset\n",
    "            gy1 = (box['y_min'] * tile_size) + y_offset\n",
    "            gx2 = (box['x_max'] * tile_size) + x_offset\n",
    "            gy2 = (box['y_max'] * tile_size) + y_offset\n",
    "            \n",
    "            draw.rectangle([gx1, gy1, gx2, gy2], outline=\"red\", width=5)\n",
    "\n",
    "    shutil.rmtree(tile_dir)\n",
    "    os.makedirs(tile_dir)\n",
    "    canvas.save(output_path)\n",
    "    print(f\"Stitched image saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c634ca-7d75-4f3a-8027-95f8a2224927",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## SPLITS IMAGES IN TILES ##############################################\n",
    "import numpy as np\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "def tile_tiff_image(\n",
    "    input_path,\n",
    "    output_dir,\n",
    "    tile_size=378,\n",
    "    overlap=50,\n",
    "    save_format='png',\n",
    "    compression=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Split a TIFF image into overlapping tiles.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_path : str\n",
    "        Path to input TIFF image\n",
    "    output_dir : str\n",
    "        Directory to save tiles\n",
    "    tile_size : int\n",
    "        Size of each tile (width and height in pixels)\n",
    "    overlap : int\n",
    "        Number of pixels to overlap between adjacent tiles\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    img = Image.open(input_path)\n",
    "    \n",
    "    width, height = img.size\n",
    "    print(f\"Image size: {width} x {height}\")\n",
    "    print(f\"Image mode: {img.mode}\")\n",
    "    print(f\"Tile size: {tile_size} x {tile_size}\")\n",
    "    print(f\"Overlap: {overlap} pixels\")\n",
    "    \n",
    "    step = tile_size - overlap\n",
    "    \n",
    "    # Calculate number of tiles\n",
    "    cols = (width - overlap + step - 1) // step\n",
    "    rows = (height - overlap + step - 1) // step\n",
    "    \n",
    "    print(f\"Creating {rows} x {cols} = {rows * cols} tiles\")\n",
    "    \n",
    "    tile_count = 0\n",
    "    \n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            # Calculate tile boundaries\n",
    "            x_start = col * step\n",
    "            y_start = row * step\n",
    "            x_end = min(x_start + tile_size, width)\n",
    "            y_end = min(y_start + tile_size, height)\n",
    "            \n",
    "            # Extract tile\n",
    "            tile = img.crop((x_start, y_start, x_end, y_end))\n",
    "            \n",
    "            # Generate filename\n",
    "            base_name = Path(input_path).stem\n",
    "            tile_filename = f\"{base_name}_tile_r{row:04d}_c{col:04d}.{save_format}\"\n",
    "            tile_path = os.path.join(output_dir, tile_filename)\n",
    "            \n",
    "            if save_format.lower() == 'tif':\n",
    "                # Save as TIFF with optional compression\n",
    "                save_params = {}\n",
    "                if compression != None:\n",
    "                    save_params['compression'] = compression.lower()\n",
    "                tile.save(tile_path, **save_params)\n",
    "            else:\n",
    "                tile.save(tile_path)\n",
    "            \n",
    "            tile_count += 1\n",
    "    \n",
    "    print(f\"\\nComplete! Created {tile_count} tiles in '{output_dir}'\")\n",
    "    return width, height, tile_size, overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca2d05c-2b06-4063-9d40-821183bfbddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 4129 x 3037\n",
      "Image mode: RGB\n",
      "Tile size: 378 x 378\n",
      "Overlap: 50 pixels\n",
      "Creating 10 x 13 = 130 tiles\n",
      "\n",
      "Complete! Created 130 tiles in '/home/kalina/moondream_finetuning/geoint_images/resized'\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚úÖ Found 1 targets\n",
      "‚ùå REJECTED: This tile is an outlier.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚ùå No targets found.\n",
      "‚úÖ Found 1 targets\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "model 'llama3.2-vision:90b' not found (status code: 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚ùå REJECTED: This tile is an outlier.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     is_verified, reason = \u001b[43mverify_with_ollama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_verified:\n\u001b[32m     70\u001b[39m         draw = ImageDraw.Draw(image)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mverify_with_ollama\u001b[39m\u001b[34m(image_path, target_object, ollama_host)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mverify_with_ollama\u001b[39m(image_path, target_object = \u001b[33m\"\u001b[39m\u001b[33mmilitary vehicle/vehicles\u001b[39m\u001b[33m\"\u001b[39m, ollama_host=\u001b[33m\"\u001b[39m\u001b[33mhttp://10.255.255.254:11440\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m    Sends an image to Ollama's Vision model for verification.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     response = \u001b[43mollama\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mllama3.2-vision:90b\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDo you see anything that looks like military vehicle or equipment in this image? Reply with \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mYes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m or \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNo\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m and a short reason.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     content = response[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     43\u001b[39m     \u001b[38;5;28mprint\u001b[39m(content.lower())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/detecting_model/lib/python3.12/site-packages/ollama/_client.py:365\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, think, logprobs, top_logprobs, format, options, keep_alive)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    319\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    320\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    331\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    332\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    333\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    334\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    363\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m      \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/detecting_model/lib/python3.12/site-packages/ollama/_client.py:189\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    187\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/detecting_model/lib/python3.12/site-packages/ollama/_client.py:133\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    131\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m    135\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mResponseError\u001b[39m: model 'llama3.2-vision:90b' not found (status code: 404)"
     ]
    }
   ],
   "source": [
    "######################################## MAIN SCRIPT ##############################################\n",
    "import io\n",
    "import base64\n",
    "import ollama\n",
    "\n",
    "image_dir = \"/home/kalina/moondream_finetuning/geoint_images/resized\"\n",
    "orig_width, orig_height, tile_size, overlap = tile_tiff_image(\"/mnt/c/Users/kalin/Downloads/gunter_data/R9C11_bccc1add-2c7a-3c95-8e0f-409376118522.tif\",image_dir)\n",
    "output_file_name = \"result.png\"\n",
    "\n",
    "def outliers_detection(box, image_width, image_height, min_area_ratio=0.02, max_area_ratio=0.85):\n",
    "    \"\"\"\n",
    "    Filter out detections that are too large (likely false positives selecting whole image)\n",
    "    or too small (likely noise).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate detection dimensions\n",
    "    det_width = (box['x_max'] - box['x_min']) * image_width\n",
    "    det_height = (box['y_max'] - box['y_min']) * image_height\n",
    "    det_area = det_width * det_height\n",
    "    image_area = image_width * image_height\n",
    "    area_ratio = det_area / image_area\n",
    "\n",
    "    # Filter by area ratio\n",
    "    if area_ratio < min_area_ratio or area_ratio > max_area_ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def verify_with_ollama(image_path, target_object = \"military vehicle/vehicles\", ollama_host=\"http://10.255.255.254:11440\"):\n",
    "    \"\"\"\n",
    "    Sends an image to Ollama's Vision model for verification.\n",
    "    \"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2-vision:90b',\n",
    "        messages=[{\n",
    "            'role': 'user',\n",
    "            'content': f\"Do you see anything that looks like military vehicle or equipment in this image? Reply with 'Yes' or 'No' and a short reason.\",\n",
    "            'images': [image_path] \n",
    "        }]\n",
    "    )\n",
    "    content = response['message']['content']\n",
    "    print(content.lower())\n",
    "    is_verified = \"yes\" in content.lower()\n",
    "    return is_verified, content\n",
    "    \n",
    "all_detections=[]\n",
    "\n",
    "#Looping through tiles\n",
    "for filename in os.listdir(image_dir):\n",
    "    image = Image.open(os.path.join(image_dir,filename))\n",
    "    width, height = image.size \n",
    "    target_object = \"military vehicle/vehicles\" \n",
    "    \n",
    "    results = model.detect(image, target_object)\n",
    "    objects = results[\"objects\"]\n",
    "    \n",
    "    if objects:\n",
    "        print(f\"‚úÖ Found {len(objects)} targets\") \n",
    "        for box in objects:\n",
    "                x1 = box['x_min']\n",
    "                y1 = box['y_min']\n",
    "                x2 = box['x_max']\n",
    "                y2 = box['y_max']\n",
    "                if outliers_detection(box, width, height):\n",
    "                    print(f\"‚ùå REJECTED: This tile is an outlier.\")\n",
    "                else:\n",
    "                    is_verified, reason = verify_with_ollama(os.path.join(image_dir, filename))\n",
    "                    if is_verified:\n",
    "                        draw = ImageDraw.Draw(image)\n",
    "                        all_detections.append({\n",
    "                            'tile_name': filename,\n",
    "                            'objects': [box]\n",
    "                        })\n",
    "                        draw.rectangle([x1*width, y1*height, x2*width, y2*height], outline=\"red\", width=5)\n",
    "                        image.show()\n",
    "            \n",
    "                    else: print(f\"‚ùå REJECTED: {reason}\")\n",
    "    else:\n",
    "        print(\"‚ùå No targets found.\")\n",
    "   \n",
    "restitch_and_draw(image_dir,output_file_name,(orig_width, orig_height), tile_size, overlap, all_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d492e7-574d-4c16-8d3d-1d2b5882eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## DOWNLOADING IMAGES FROM THE BACKET ##############################################\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_and_download_geoint_data(since_date=\"2026-01-01T00:00:00Z\", download_dir=\"geoint_images\"):\n",
    "    \"\"\"\n",
    "    Fetches GEOINT data from the API and downloads pictures from bucket URLs.\n",
    "    \n",
    "    Args:\n",
    "        since_date: ISO format date string for the 'since' parameter\n",
    "        download_dir: Directory where files will be downloaded\n",
    "    \"\"\"\n",
    "    # Create download directory if it doesn't exist\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    \n",
    "    # API endpoint\n",
    "    url = f\"https://europe-west3-soldier-tracker.cloudfunctions.net/geoint-coms/read?since={since_date}\"\n",
    "    \n",
    "    try:\n",
    "        # Fetch data from API\n",
    "        print(f\"Fetching data from API...\")\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Check if request was successful\n",
    "        if data.get(\"status\") != \"success\":\n",
    "            print(f\"API returned non-success status: {data.get('status')}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Found {data.get('count', 0)} record(s)\")\n",
    "        \n",
    "        # Process each record\n",
    "        for record in data.get(\"data\", []):\n",
    "            uuid = record.get(\"uuid\")\n",
    "            bucket_url = record.get(\"bucket_url\")\n",
    "            insert_date = record.get(\"insert_date\")\n",
    "            \n",
    "            print(f\"\\nProcessing record {uuid}\")\n",
    "            print(f\"Insert date: {insert_date}\")\n",
    "            print(f\"Downloading from: {bucket_url}\")\n",
    "            \n",
    "            # Download the zip file\n",
    "            zip_response = requests.get(bucket_url)\n",
    "            zip_response.raise_for_status()\n",
    "            \n",
    "            # Create a directory for this specific record\n",
    "            record_dir = os.path.join(download_dir, insert_date)\n",
    "            os.makedirs(record_dir, exist_ok=True)\n",
    "            \n",
    "            # Extract zip file\n",
    "            with zipfile.ZipFile(io.BytesIO(zip_response.content)) as zip_file:\n",
    "                # Extract all files\n",
    "                zip_file.extractall(record_dir)\n",
    "                print(f\"Extracted {len(zip_file.namelist())} file(s) to {record_dir}\")\n",
    "                \n",
    "        print(f\"\\nDownload complete! Files saved to '{download_dir}' directory\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "    except zipfile.BadZipFile as e:\n",
    "        print(f\"Error extracting zip file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the function\n",
    "    fetch_and_download_geoint_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
